---
name: Deploy Iceberg Table

"on":
  push:
    branches:
      - main

jobs:
  deploy:
    runs-on: ubuntu-latest

    permissions:
      id-token: write  # Needed for OIDC
      contents: read

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: arn:aws:iam::980921712180:role/WebConsole
          aws-region: ap-south-1
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3

      - name: Install necessary utilities
        run: |
          sudo apt-get update
          sudo apt-get install -y coreutils
          sudo apt-get install -y sudo

      - name: Set up Spark environment (including JARs for Iceberg)
        run: |
          # Create directory for Spark jars
          # Create directory for Spark jars using Python
          python -c "import os; os.makedirs('/tmp/spark/jars', exist_ok=True)"

          # Download JAR files for Iceberg and Hadoop AWS
          curl -L -o /tmp/spark/jars/iceberg-spark-runtime-3.3_2.12-1.4.2.jar https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-3.3_2.12/1.4.2/iceberg-spark-runtime-3.3_2.12-1.4.2.jar
          curl -L -o /tmp/spark/jars/hadoop-aws-3.3.2.jar https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.2/hadoop-aws-3.3.2.jar
          curl -L -o /tmp/spark/jars/aws-java-sdk-bundle-1.11.1054.jar https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.11.1054/aws-java-sdk-bundle-1.11.1054.jar
      
      - name: Install Spark (and dependencies)
        run: |
          echo "Downloading Spark 3.5.5..."
          curl -L -o spark.tgz https://dlcdn.apache.org/spark/spark-3.5.5/spark-3.5.5-bin-hadoop3.tgz
          
          echo "Extracting Spark..."
          tar -xzf spark.tgz
          sudo mv spark-3.5.5-bin-hadoop3 /usr/local/spark

          echo "Setting up Spark environment..."
          echo "SPARK_HOME=/usr/local/spark" >> $GITHUB_ENV
          echo "PATH=/usr/local/spark/bin:\$PATH" >> $GITHUB_ENV
          echo "PYSPARK_PYTHON=python" >> $GITHUB_ENV
          echo "PYSPARK_DRIVER_PYTHON=python" >> $GITHUB_ENV
      
      - name: Install dependencies
        run: |
          pip install pyspark
          pip install boto3
          pip install pyyaml

      - name: Setup Python and Spark (or use Glue Job trigger here)
        run: |
          echo "ðŸ”§ Running Iceberg Table Creation Script..."
          python src/glue_etl/bootstrap/create_iceberg_tables.py \
            iceberg_tables/customers.yml \
            s3://glue-bucket-dev-prod-bucket-march2025/warehouse/
